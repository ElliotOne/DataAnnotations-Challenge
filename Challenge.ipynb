{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 requests-2.32.3 urllib3-2.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4->bs4)\n",
      "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
      "Installing collected packages: typing-extensions, soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.13.3 bs4-0.0.2 soupsieve-2.6 typing-extensions-4.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data from URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "████████░     ████████░   ██████████░    ███████░  ██░           ███░ ███░    ███░ ██░     ██░\n",
      "██░     ██░ ███░     ███░ ██░          ███░    ██░ ███░   ███░   ██░    ██░  ██░   ██░     ██░\n",
      "██░     ██░ ██░       ██░ ██░         ███░          ██░  █████░ ███░     ██░██░    ██░     ██░\n",
      "████████░   ██░       ██░ ████████░   ██░           ███░ ██░██░ ██░       ███░     ██████████░\n",
      "██░     ██░ ██░       ██░ ██░         ███░           ██░██░ ██░██░       ██░██░    ██░     ██░\n",
      "██░     ██░ ███░     ███░ ██░          ███░    ██░   ████░   ████░      ██░  ██░   ██░     ██░\n",
      "████████░     ████████░   ██████████░    ███████░     ██░     ██░     ███░    ███░ ██░     ██░\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_unicode_grid(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error fetching the document\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    table = soup.find_all('tr')\n",
    "\n",
    "    positions = []\n",
    "    for row in table:\n",
    "        columns = row.find_all('td')\n",
    "        if len(columns) == 3:\n",
    "            try:\n",
    "                x = int(columns[0].text.strip())  # x-coordinate\n",
    "                char = columns[1].text.strip()  # Unicode character\n",
    "                y = int(columns[2].text.strip())  # y-coordinate\n",
    "                positions.append((x, y, char))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    if not positions:\n",
    "        print(\"No valid data found\")\n",
    "        return\n",
    "\n",
    "    min_x = min(positions, key=lambda p: p[0])[0]\n",
    "    min_y = min(positions, key=lambda p: p[1])[1]\n",
    "    max_x = max(positions, key=lambda p: p[0])[0]\n",
    "    max_y = max(positions, key=lambda p: p[1])[1]\n",
    "\n",
    "    grid_width = max_x - min_x + 1\n",
    "    grid_height = max_y - min_y + 1\n",
    "    grid = [[' ' for _ in range(grid_width)] for _ in range(grid_height)]\n",
    "\n",
    "    for x, y, char in positions:\n",
    "        grid[y - min_y][x - min_x] = char\n",
    "\n",
    "    for row in reversed(grid):\n",
    "        print(''.join(row))\n",
    "\n",
    "url = 'https://docs.google.com/document/d/e/2PACX-1vQGUck9HIFCyezsrBSnmENk5ieJuYwpt7YHYEzeNJkIb9OSDdx-ov2nRNReKQyey-cwJOoEKUhLmN9z/pub'\n",
    "fetch_unicode_grid(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data from local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "████████░     ████████░   ██████████░    ███████░  ██░           ███░ ███░    ███░ ██░     ██░\n",
      "██░     ██░ ███░     ███░ ██░          ███░    ██░ ███░   ███░   ██░    ██░  ██░   ██░     ██░\n",
      "██░     ██░ ██░       ██░ ██░         ███░          ██░  █████░ ███░     ██░██░    ██░     ██░\n",
      "████████░   ██░       ██░ ████████░   ██░           ███░ ██░██░ ██░       ███░     ██████████░\n",
      "██░     ██░ ██░       ██░ ██░         ███░           ██░██░ ██░██░       ██░██░    ██░     ██░\n",
      "██░     ██░ ███░     ███░ ██░          ███░    ██░   ████░   ████░      ██░  ██░   ██░     ██░\n",
      "████████░     ████████░   ██████████░    ███████░     ██░     ██░     ███░    ███░ ██░     ██░\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_unicode_grid_from_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        html_content = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    table = soup.find_all('tr')\n",
    "\n",
    "    positions = []\n",
    "    for row in table:\n",
    "        columns = row.find_all('td')\n",
    "        if len(columns) == 3:\n",
    "            try:\n",
    "                x = int(columns[0].text.strip())  # x-coordinate\n",
    "                char = columns[1].text.strip()  # Unicode character\n",
    "                y = int(columns[2].text.strip())  # y-coordinate\n",
    "                positions.append((x, y, char))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    if not positions:\n",
    "        print(\"No valid data found\")\n",
    "        return\n",
    "\n",
    "    min_x = min(positions, key=lambda p: p[0])[0]\n",
    "    min_y = min(positions, key=lambda p: p[1])[1]\n",
    "    max_x = max(positions, key=lambda p: p[0])[0]\n",
    "    max_y = max(positions, key=lambda p: p[1])[1]\n",
    "\n",
    "    grid_width = max_x - min_x + 1\n",
    "    grid_height = max_y - min_y + 1\n",
    "    grid = [[' ' for _ in range(grid_width)] for _ in range(grid_height)]\n",
    "\n",
    "    for x, y, char in positions:\n",
    "        grid[y - min_y][x - min_x] = char\n",
    "\n",
    "    for row in reversed(grid):\n",
    "        print(''.join(row))\n",
    "\n",
    "# Usage\n",
    "fetch_unicode_grid_from_file('Data.html')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
